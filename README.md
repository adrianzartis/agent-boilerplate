# Agent Boilerplate

This repository provides a minimal FastAPI application showcasing how to build
agents with the [OpenAI Agents SDK](https://github.com/openai/openai-agents).
Two simple agents are orchestrated together: one summarises text and another
creates a follow-up question. All configuration and prompt files live outside
the Python modules so the structure can be easily reused.

## Setup

1. Install dependencies:
   ```bash
   pip install -e .
   ```
2. Copy `.env.example` to `.env` and set your API key:
   ```bash
   cp .env.example .env
   # edit the file and set LLM_API_KEY with your OpenAI key
   ```
3. Start the server:
   ```bash
   uvicorn src.main:app --reload
   ```

Open `http://localhost:8000/docs` to explore the API. The `/api/agent-one/run`
endpoint lets you paste some text and try the multi-agent workflow directly
from the Swagger UI. It returns both the summary and a follow-up question
generated by a second agent.

The `FollowupOutput` schema also contains a `kind` field indicating if the
question is open ended or can be answered with yes/no.

Pydantic models describing the LLM responses live in `src/schemas.py`. The
`FollowupOutput` model shows how to use `Literal` to constrain values returned
by the language model. FastAPI routers for each agent are defined in their
respective `router.py` modules and are collected by `src/agent.py`. The
application entry point in `src/main.py` simply mounts these routers and adds
some basic middleware.

## Extending

Duplicate the `agent_one` package to start a new agent. Update the prompt path
in `config/config.yaml` and register the router in `src/agent.py`. Each agent
package can define multiple `Agent` objects inside `agent.py` and orchestrate
them in `runner.py`.
